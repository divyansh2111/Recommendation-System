{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'ecommerce-behavior-data-from-multi-category-store:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F411512%2F835452%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240303%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240303T205424Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D6e716936e01ba6b04b1b6d4337cbb7d2017c0aa7f3902a7a2b450da4e5fdd09f12dc5aeb5c4c71bb51e7248c9398e6e2e4077725cae75b9f191f66d9cf869b85a85b490450fd20cee01985dc6c1b94068484fa1c3969264188ddf1b96514bd40c4a97d56c430f8dba86400c3d1e9f2558a2c3483960c438889f468f8ce9762179616206f27a3ca6d6d066d24bd2e4704bfbc875033cfc8d48f80115bf4911896fad6711cceb21bd7d2a45ed47d55386fadbf126191ec6e3e30df32d564512b04c30b7a24f0dedb73508a321980bae28645a94e5d7412c27a51f6fa62edf14a7a16e33aa5d592d6eed6783fc412c626a0153714fdfaed982aabe9cd7fc09eb1b4'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "l-omQvrKGLfr"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommendation Engine"
      ],
      "metadata": {
        "id": "vqTOP7SEGLf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.context import SparkContext\n",
        "from pyspark.sql.functions import *\n",
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql.types import DoubleType\n",
        "import matplotlib.pyplot as plt\n",
        "import pyarrow"
      ],
      "metadata": {
        "trusted": true,
        "id": "r01ep2u4GLf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SparkSession.builder.appName(\"Product_Recommendation\") \\\n",
        ".config (\"spark.sql.shuffle.partitions\", \"16\") \\\n",
        ".config(\"spark.driver.maxResultSize\",\"4g\") \\\n",
        ".config (\"spark.sql.execution.arrow.enabled\", \"true\") \\\n",
        ".config(\"spark.driver.memory\", \"4g\") \\\n",
        ".config(\"spark.executor.cores\", \"4\") \\\n",
        ".getOrCreate()\n",
        "\n",
        "sc.sparkContext.setLogLevel(\"ERROR\")"
      ],
      "metadata": {
        "id": "ponXcnJaGLf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = sc.read.option('header', True).csv('/kaggle/input/ecommerce-behavior-data-from-multi-category-store/2019-Nov.csv')"
      ],
      "metadata": {
        "id": "FRhfdiLmGLf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "id": "099GlDHkGLf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "tLZQnymHGLf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select([count(when(isnull(c), c)).alias(c) for c in df.columns]).show()"
      ],
      "metadata": {
        "id": "4-qFUj5-GLf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy('event_type').count().show()"
      ],
      "metadata": {
        "id": "DH5KybWlGLgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "events = df.groupBy('event_type').count().toPandas()\n",
        "events.plot(kind='pie', y='count', labels=events['event_type'], autopct='%1.2f%%', figsize=(5, 5))"
      ],
      "metadata": {
        "id": "vJsWpNYYGLgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(f.countDistinct(\"product_id\")).show()"
      ],
      "metadata": {
        "id": "RSP3_wjsGLgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('product_id').agg(f.collect_set('category_id'))\\\n",
        "                        .filter(size(col('collect_set(category_id)')) == 1).count()"
      ],
      "metadata": {
        "id": "RrxnMTldGLgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(f.countDistinct(\"category_id\")).show()"
      ],
      "metadata": {
        "id": "Lo34ymkOGLgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(subset=['category_id']).select(f.count(\"category_code\")).show()"
      ],
      "metadata": {
        "id": "OT2przt1GLgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(f.countDistinct(\"category_code\")).show()"
      ],
      "metadata": {
        "id": "S4SB66fYGLgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(f.countDistinct(\"user_id\")).show()"
      ],
      "metadata": {
        "id": "dsBMgzPoGLgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(f.countDistinct(\"user_session\")).show()"
      ],
      "metadata": {
        "id": "andn8CXeGLgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('event_time', to_timestamp('event_time'))\n",
        "df = df.withColumn('date', date_format(\"event_time\", \"yyyy-MM-dd\"))\n",
        "\n",
        "sessions = df.groupby('date').agg(countDistinct('user_session')).toPandas()\n",
        "sessions.sort_values('date').plot(x='date', figsize=(8, 4))"
      ],
      "metadata": {
        "id": "rC4UC31fGLgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interactions = df.groupby(['user_id', 'product_id']).agg(sum(when(df['event_type'] == 'view', 1)).alias('views'),\n",
        "                                                         sum(when(df['event_type'] == 'cart', 1)).alias('carts'),\n",
        "                                                         sum(when(df['event_type'] == 'purchase', 1)).alias('purchases'))\n",
        "\n",
        "interactions.sort('carts', ascending=False).show()"
      ],
      "metadata": {
        "scrolled": true,
        "id": "JOyOhXf4GLgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess"
      ],
      "metadata": {
        "id": "e6EZL3QxGLgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(df):\n",
        "\n",
        "    # Change data types\n",
        "    df = df.withColumn('event_time', to_timestamp('event_time'))\n",
        "    df = df.withColumn('user_id', col('user_id').cast('integer'))\n",
        "    df = df.withColumn('product_id', col('product_id').cast('integer'))\n",
        "    df = df.withColumn('category_id', col('category_id').cast('long'))\n",
        "\n",
        "    # Limit the number of carts to 1 per session for each user-product pair\n",
        "    cart_df = df.filter(col('event_type') == 'cart')\n",
        "    df = df.filter(col('event_type') != 'cart')\n",
        "    cart_df = cart_df.dropDuplicates(subset=['product_id', 'user_id', 'user_session'])\n",
        "    df = df.union(cart_df)\n",
        "\n",
        "    # Split category codes into sub categories\n",
        "    #df = df.withColumn('category', split(df['category_code'], '\\.').getItem(0)) \\\n",
        "    #   .withColumn('sub_category', split(df['category_code'], '\\.').getItem(1)) \\\n",
        "    #   .withColumn('sub_sub_category', split(df['category_code'], '\\.').getItem(2))\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "Jqn5v1IdGLgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = preprocess(df)"
      ],
      "metadata": {
        "id": "zo65mEV0GLgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "metadata": {
        "id": "BbSJaLWXGLgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def product_features(df):\n",
        "\n",
        "    # Calculate several metrics for products with the aggregate function\n",
        "    df = df.groupby('product_id').agg(first('category_id').alias('category_id'),\n",
        "                                      first('category_code').alias('category_code'),\n",
        "                                      count(when(df['event_type'] == 'view', True)).alias('views'),\n",
        "                                      count(when(df['event_type'] == 'cart', True)).alias('carts'),\n",
        "                                      count(when(df['event_type'] == 'purchase', True)).alias('purchases'),\n",
        "                                      mean('price').alias('price'),\n",
        "                                      min('event_time').alias('first_date'),\n",
        "                                      max('event_time').alias('last_date'))\n",
        "\n",
        "    # Calculate interaction rates\n",
        "    df = df.withColumn('purchase_per_view', df['purchases'] / df['views'])\n",
        "    df = df.withColumn('cart_per_view', df['carts'] / df['views'])\n",
        "    df = df.withColumn('purchase_per_cart', when(df['carts'] == 0, df['purchases']).otherwise(df['purchases'] / df['carts']))\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "K-eGRjeRGLgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def category_features(df):\n",
        "\n",
        "    # Calculate the average product price for each category\n",
        "    products = df.dropDuplicates(subset=['product_id'])\n",
        "    products = products.groupby('category_id').agg(avg('price').alias('average_price'))\n",
        "\n",
        "    # Calculate several metrics for categories with the aggregate function\n",
        "    df = df.groupby('category_id').agg(first('category_code').alias('category_code'),\n",
        "                                       countDistinct('product_id').alias('number_of_products'),\n",
        "                                       count(when(df['event_type'] == 'view', True)).alias('views'),\n",
        "                                       count(when(df['event_type'] == 'cart', True)).alias('carts'),\n",
        "                                       count(when(df['event_type'] == 'purchase', True)).alias('purchases'))\n",
        "\n",
        "    # Calculate interaction rates\n",
        "    df = df.withColumn('purchase_per_view', df['purchases'] / df['views'])\n",
        "    df = df.withColumn('cart_per_view', df['carts'] / df['views'])\n",
        "    df = df.withColumn('purchase_per_cart', when(df['carts'] == 0, df['purchases']).otherwise(df['purchases'] / df['carts']))\n",
        "\n",
        "    df = df.join(products, on='category_id')\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "oaSLKEhzGLgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def user_features(df):\n",
        "\n",
        "    # Calculate several metrics for users with the aggregate function\n",
        "    df = df.groupby('user_id').agg(count(when(df['event_type'] == 'view', True)).alias('views'),\n",
        "                                   count(when(df['event_type'] == 'cart', True)).alias('carts'),\n",
        "                                   count(when(df['event_type'] == 'purchase', True)).alias('purchases'),\n",
        "                                   countDistinct(when(df['event_type'] == 'view', col('product_id'))).alias('distinct_products_viewed'),\n",
        "                                   countDistinct(when(df['event_type'] == 'cart', col('product_id'))).alias('distinct_products_carted'),\n",
        "                                   countDistinct(when(df['event_type'] == 'purchase', col('product_id'))).alias('distinct_products_purchased'),\n",
        "                                   mean(when(df['event_type'] == 'view', col('price'))).alias('average_price_viewed'),\n",
        "                                   mean(when(df['event_type'] == 'purchase', col('price'))).alias('average_price_purchased'),\n",
        "                                   mean(when(df['event_type'] == 'view', col('relative_price'))).alias('avg_relative_price_viewed'),\n",
        "                                   mean(when(df['event_type'] == 'purchase', col('relative_price'))).alias('avg_relative_price_purchased'),\n",
        "                                   min('event_time').alias('first_date'),\n",
        "                                   max('event_time').alias('last_date'))\n",
        "\n",
        "    # Calculate interaction rates\n",
        "    df = df.withColumn('purchase_per_view', when(df['views'] == 0, df['purchases']).otherwise(df['purchases'] / df['views']))\n",
        "    df = df.withColumn('cart_per_view', when(df['views'] == 0, df['carts']).otherwise(df['carts'] / df['views']))\n",
        "    df = df.withColumn('purchase_per_cart', when(df['carts'] == 0, df['purchases']).otherwise(df['purchases'] / df['carts']))\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "vEk1Bw9MGLgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def category_smoothener(categories, mean, attr, rate, min_sample_size=1000):\n",
        "\n",
        "    # Weighted average of category value and overall mean\n",
        "    categories = categories.withColumn(rate, when(categories[attr] < min_sample_size, ((categories[rate] * categories[attr]) + (mean * (min_sample_size - categories[attr]))) / min_sample_size).otherwise(categories[rate]))\n",
        "\n",
        "    return categories"
      ],
      "metadata": {
        "id": "JOcvSp7ZGLgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def product_smoothener(products, categories, attr, rate, min_sample_size=1000):\n",
        "\n",
        "    category_rate = rate + '_cat'\n",
        "    categories = categories.withColumnRenamed(rate, category_rate)\n",
        "    products = products.join(categories['category_id', category_rate], on='category_id')\n",
        "\n",
        "    # Weighted average of product value and category value\n",
        "    products = products.withColumn(rate, when(products[attr] < min_sample_size, ((products[rate] * products[attr]) + (products[category_rate] * (min_sample_size - products[attr]))) / min_sample_size).otherwise(products[rate]))\n",
        "\n",
        "    products = products.drop(category_rate)\n",
        "    return products"
      ],
      "metadata": {
        "id": "FFjcgsfBGLgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calculate_relative_price(products):\n",
        "\n",
        "    categories = products.groupby('category_id').agg(percentile_approx('price', 0.25, 1000).alias('Q1'),\n",
        "                                                     percentile_approx('price', 0.5, 1000).alias('median'),\n",
        "                                                     percentile_approx('price', 0.75, 1000).alias('Q3'))\n",
        "    # Interquartile range\n",
        "    categories = categories.withColumn('IQR', col('Q3') - col('Q1'))\n",
        "    categories = categories.withColumn('IQR', when(col('IQR') < 1, 1).otherwise(col('IQR')))\n",
        "\n",
        "    # Calculate relative price\n",
        "    products = products.join(categories, on='category_id')\n",
        "    products = products.withColumn('relative_price', (col('price') - col('median')) / col('IQR'))\n",
        "\n",
        "    # In order to avoid extreme values, set the max possible value to 5\n",
        "    products = products.withColumn('relative_price', when(col('relative_price') > 5, 5).otherwise(col('relative_price')))\n",
        "\n",
        "    # Set the min possible value to -5\n",
        "    products = products.withColumn('relative_price', when(col('relative_price') < -5, -5).otherwise(col('relative_price')))\n",
        "\n",
        "    products = products.select('product_id', 'relative_price')\n",
        "    return products"
      ],
      "metadata": {
        "id": "R3UkN0PBGLgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "products = product_features(df)\n",
        "categories = category_features(df)"
      ],
      "metadata": {
        "id": "KekHPErfGLgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relative_prices = calculate_relative_price(products)\n",
        "\n",
        "df = df.join(relative_prices, on='product_id')\n",
        "products = products.join(relative_prices, on='product_id')"
      ],
      "metadata": {
        "id": "TB1h21HfGLgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_purchase_per_view = events[events['event_type'] == 'purchase']['count'].values[0] / events[events['event_type'] == 'view']['count'].values[0]\n",
        "avg_cart_per_view = events[events['event_type'] == 'cart']['count'].values[0] / events[events['event_type'] == 'view']['count'].values[0]\n",
        "avg_purchase_per_cart = events[events['event_type'] == 'purchase']['count'].values[0] / events[events['event_type'] == 'cart']['count'].values[0]\n",
        "\n",
        "categories = category_smoothener(categories, avg_purchase_per_view, 'views', 'purchase_per_view', 2000)\n",
        "categories = category_smoothener(categories, avg_cart_per_view, 'views', 'cart_per_view', 2000)\n",
        "categories = category_smoothener(categories, avg_purchase_per_cart, 'carts', 'purchase_per_cart', 200)"
      ],
      "metadata": {
        "id": "uaD1KN7pGLgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "products = product_smoothener(products, categories, 'views', 'purchase_per_view', 1000)\n",
        "products = product_smoothener(products, categories, 'views', 'cart_per_view', 1000)\n",
        "products = product_smoothener(products, categories, 'carts', 'purchase_per_cart', 100)"
      ],
      "metadata": {
        "id": "oXkkCEmTGLgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users = user_features(df)"
      ],
      "metadata": {
        "id": "nSGsOJdeGLgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "products.sort('purchases', ascending=False).toPandas().head(50)"
      ],
      "metadata": {
        "id": "7_bwBF6lGLga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collaborative Filtering"
      ],
      "metadata": {
        "id": "_3pTsnT2GLga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the timestamp of the most recent event in the df\n",
        "last_date = df.agg(max('event_time')).collect()[0][0]\n",
        "df = df.withColumn('last_date', lit(last_date))\n",
        "\n",
        "# Calculate the recency of each event in terms of days\n",
        "df = df.withColumn('recency', (col('last_date').cast('double') - col('event_time').cast('double')) / 86400)\n",
        "df = df.drop('last_date')\n",
        "\n",
        "# Half-life decay function\n",
        "df = df.withColumn('recency_coef', expr('exp(ln(0.5)*recency/20)'))"
      ],
      "metadata": {
        "scrolled": true,
        "id": "T-qweqsSGLgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interactions = df.groupby(['user_id', 'product_id']).agg(sum(when(df['event_type'] == 'view', 1) * df['recency_coef']).alias('views'),\n",
        "                                                         sum(when(df['event_type'] == 'cart', 1) * df['recency_coef']).alias('carts'),\n",
        "                                                         sum(when(df['event_type'] == 'purchase', 1) * df['recency_coef']).alias('purchases'))\n",
        "interactions = interactions.na.fill(0)"
      ],
      "metadata": {
        "id": "R7iMOtbIGLgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_interaction_matrix(df, view_weight=0.1, cart_weight=0.3, purchase_weight=1.0):\n",
        "\n",
        "    df = df.withColumn('interaction', view_weight * col('views') + cart_weight * col('carts') + purchase_weight * col('purchases'))\n",
        "\n",
        "    df = df.withColumn('interaction', log10(col('interaction') + 1))\n",
        "\n",
        "    df = df.withColumn('interaction', when(col('interaction') > 2, 2).otherwise(col('interaction')))\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "2O5Kr_N4GLgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interaction_matrix = calculate_interaction_matrix(interactions)"
      ],
      "metadata": {
        "scrolled": true,
        "id": "R5913RggGLgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interaction_matrix.sort('interaction', ascending=False).show()"
      ],
      "metadata": {
        "id": "QSwXjfNZGLgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "def cross_validate_als(interaction_matrix):\n",
        "\n",
        "    als = ALS(userCol='user_id', itemCol='product_id', ratingCol='interaction',\n",
        "              nonnegative=True, coldStartStrategy='drop', implicitPrefs=True)\n",
        "\n",
        "    param_grid = ParamGridBuilder() \\\n",
        "        .addGrid(als.rank, [5, 10, 15, 20]) \\\n",
        "        .addGrid(als.regParam, [0.005, 0.01, 0.05, 0.1]) \\\n",
        "        .addGrid(als.alpha, [0, 1.0, 5.0]) \\\n",
        "        .build()\n",
        "\n",
        "    evaluator = RegressionEvaluator(metricName='rmse', labelCol='interaction', predictionCol='prediction')\n",
        "\n",
        "    cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=5, collectSubModels=False)\n",
        "\n",
        "    pipeline = Pipeline(stages=[cv])\n",
        "\n",
        "    model = pipeline.fit(interaction_matrix)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "adQ4tRDaGLge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = cross_validate_als(interaction_matrix)\n",
        "\n",
        "bestModel = model.stages[0].bestModel\n",
        "\n",
        "predictions = bestModel.transform(interaction_matrix)\n",
        "\n",
        "evaluator = RegressionEvaluator(metricName='rmse', labelCol='interaction', predictionCol='prediction')\n",
        "rmse = evaluator.setMetricName('rmse').evaluate(predictions)\n",
        "mae = evaluator.setMetricName('mae').evaluate(predictions)\n",
        "print(' rmse:' + str(rmse) + ' mae:' + str(mae))\n",
        "\n",
        "regParam = bestModel._java_obj.parent().getRegParam()\n",
        "rank = bestModel._java_obj.parent().getRank()\n",
        "alpha = bestModel._java_obj.parent().getAlpha()\n",
        "print('rank:' + str(rank) + ' regParam:' + str(regParam) + ' alpha:' + str(alpha))"
      ],
      "metadata": {
        "id": "IlVTc5ZXGLgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "def simple_als(interaction_matrix):\n",
        "\n",
        "    # Train-test split\n",
        "    (train, test) = interaction_matrix.randomSplit([0.8, 0.2])\n",
        "\n",
        "    # Initialize the model with the optimized parameters\n",
        "    als = ALS(userCol='user_id', itemCol='product_id', ratingCol='interaction',\n",
        "              alpha=1, regParam=0.005, rank=15, implicitPrefs=True,\n",
        "              nonnegative=True, coldStartStrategy='drop')\n",
        "\n",
        "    # Fit the ALS model on the ratings data\n",
        "    model = als.fit(train)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.transform(test)\n",
        "\n",
        "    # Calculate the RMSE and MAE metrics\n",
        "    evaluator = RegressionEvaluator(metricName='rmse', labelCol='interaction', predictionCol='prediction')\n",
        "    rmse = evaluator.evaluate(predictions)\n",
        "    mae = evaluator.setMetricName('mae').evaluate(predictions)\n",
        "    print('test rmse:' + str(rmse) + ' mae:' + str(mae))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "P0dS3MNbGLgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "als_model = simple_als(interaction_matrix)"
      ],
      "metadata": {
        "id": "wDOlZqPGGLgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recommend Products for Users"
      ],
      "metadata": {
        "id": "Es0hu2xyGLgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_subset = [565606905, 570112140, 564068124]\n",
        "recommendations = sc.createDataFrame([(user, 0) for user in user_subset], ['user_id', 'product_id'])\n",
        "recommendations = als_model.recommendForUserSubset(recommendations, 500)"
      ],
      "metadata": {
        "id": "W7n0bp6JGLgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommendations.show()"
      ],
      "metadata": {
        "id": "kz0YxDNGGLgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recs_for_user_1 = sc.createDataFrame(recommendations.collect()[1][1])"
      ],
      "metadata": {
        "id": "WMMvHQRTGLgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interactions.filter(col('user_id') == 564068124).sort('purchases', ascending=False).show()"
      ],
      "metadata": {
        "id": "2QhYw3aiGLgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_recommendation_scores_for_user(user_id, recs, products, users, coef_als_score=0.8, coef_conversion_rate=0.1, coef_spending_habit=0.1, coef_spending_booster=0.05):\n",
        "\n",
        "    recs = recs.join(products['product_id', 'purchase_per_view', 'relative_price'], on='product_id')\n",
        "\n",
        "    user_avg_relative_price = users.filter(col('user_id') == user_id)['user_id', 'avg_relative_price_purchased'].collect()[0][1]\n",
        "\n",
        "\n",
        "    # Scale CF rating score, ranges from 0 to 2\n",
        "    recs = recs.withColumn('rating', col('rating') / 2)\n",
        "\n",
        "    # Scale purchase_per_view rate, ranges from 0 to 0.075\n",
        "    recs = recs.withColumn('purchase_per_view', col('purchase_per_view') / 0.075)\n",
        "\n",
        "    # Scale relative price value, ranges from -5 to 5\n",
        "    recs = recs.withColumn('relative_price', (col('relative_price') + 5) / 10)\n",
        "\n",
        "    # Scale users average relative price value, ranges from -1 to 1\n",
        "    user_avg_relative_price = (user_avg_relative_price + 1) / 2\n",
        "\n",
        "\n",
        "    # Calculate the recommendation scores\n",
        "    recs = recs.withColumn('recommendation_score', ((recs['rating'] * coef_als_score) + (recs['purchase_per_view'] * coef_conversion_rate) - abs(user_avg_relative_price + coef_spending_booster - recs['relative_price']) * coef_spending_habit) / (coef_als_score + coef_conversion_rate + coef_spending_habit))\n",
        "\n",
        "\n",
        "    # Scale back CF rating score, ranges from 0 to 2\n",
        "    recs = recs.withColumn('rating', col('rating') * 2)\n",
        "\n",
        "    # Scale back purchase_per_view rate, ranges from 0 to 0.075\n",
        "    recs = recs.withColumn('purchase_per_view', col('purchase_per_view') * 0.075)\n",
        "\n",
        "    # Scale back relative price value, ranges from -1 to 1\n",
        "    recs = recs.withColumn('relative_price', col('relative_price') * 2 - 1)\n",
        "\n",
        "    # Scale back average relative price value, ranges from -5 to 5\n",
        "    user_avg_relative_price = user_avg_relative_price * 10 - 5\n",
        "\n",
        "    return recs"
      ],
      "metadata": {
        "id": "k3KYpRfCGLgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recs_user = calculate_recommendation_scores_for_user(564068124, recs_for_user_1, products, users)"
      ],
      "metadata": {
        "id": "i8N2C_VJGLgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Products with the highest recommendation scores\n",
        "\n",
        "recs_user.sort('recommendation_score', ascending=False).show()"
      ],
      "metadata": {
        "id": "iHwfWxQpGLgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_interacted_products = recs_user.join(interactions.filter(col('user_id') == 564068124), on='product_id', how='leftanti')\n",
        "\n",
        "# Non-interacted products with the highest recommendation scores\n",
        "non_interacted_products.sort('recommendation_score', ascending=False).show()"
      ],
      "metadata": {
        "id": "pN4OhWfBGLgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recommend Products for Products"
      ],
      "metadata": {
        "id": "_ROzHdvCGLgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.feature import Normalizer\n",
        "from pyspark.ml.feature import SQLTransformer\n",
        "\n",
        "product_vectors = best_model.itemFactors\n",
        "product_vectors = product_vectors.rdd.map(lambda row: (row[0], Vectors.dense(row[1])))\n",
        "product_vectors = product_vectors.toDF(['product_id', 'features'])\n",
        "\n",
        "assembler = VectorAssembler(inputCols=['features'], outputCol='vector')\n",
        "product_vectors = assembler.transform(product_vectors)\n",
        "\n",
        "normalizer = Normalizer(inputCol='vector', outputCol='norm_vector')\n",
        "product_vectors = normalizer.transform(product_vectors)\n",
        "\n",
        "product_vector = product_vectors.where(col('product_id') == 5100067).select('norm_vector').collect()[0][0]\n",
        "product_vector"
      ],
      "metadata": {
        "id": "SkpwveUaGLgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
        "\n",
        "brp = BucketedRandomProjectionLSH(inputCol=\"norm_vector\", outputCol=\"neighbors\", numHashTables=5, bucketLength=0.1)\n",
        "brp_model = brp.fit(product_vectors)\n",
        "\n",
        "query = product_vectors.filter(col('product_id') == 5100067).select('norm_vector').first()[0]\n",
        "neighbors = brp_model.approxNearestNeighbors(product_vectors, query, numNearestNeighbors=50)"
      ],
      "metadata": {
        "id": "6c3y2_dOGLgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neighbors.select('product_id', 'distCol').show(truncate=False)"
      ],
      "metadata": {
        "id": "wPGgxIGxGLgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_recommendation_scores_for_products(recs, products, coef_distance_score=0.8, coef_conversion_rate=0.1, coef_relative_price=0.1, coef_spending_booster=0.05):\n",
        "\n",
        "    recs = recs.join(products['product_id', 'purchase_per_view', 'relative_price'], on='product_id')\n",
        "\n",
        "    # Scale distance of nearest neigbors in the unit vector space, ranges from 0 to sqrt(2)\n",
        "    recs = recs.withColumn('distCol', (math.sqrt(2) - col('distCol')) / math.sqrt(2))\n",
        "\n",
        "    # Scale purchase_per_view rate, ranges from 0 to 0.075\n",
        "    recs = recs.withColumn('purchase_per_view', col('purchase_per_view') / 0.075)\n",
        "\n",
        "    # Scale relative price value, ranges from -5 to 5\n",
        "    recs = recs.withColumn('relative_price', (col('relative_price') + 5) / 10)\n",
        "\n",
        "    # Find the relative price of the chosen product\n",
        "    product_relative_price = recs.filter(col('distCol') == 1)['product_id', 'relative_price'].collect()[0][1]\n",
        "\n",
        "    # Scale product's average relative price value, ranges from -5 to 5\n",
        "    product_relative_price = (product_relative_price + 5) / 10\n",
        "\n",
        "\n",
        "    # Calculate the recommendation scores\n",
        "    recs = recs.withColumn('recommendation_score', ((recs['distCol'] * coef_distance_score) + (recs['purchase_per_view'] * coef_conversion_rate) - abs(product_relative_price + coef_spending_booster - recs['relative_price']) * coef_relative_price) / (coef_distance_score + coef_conversion_rate + coef_relative_price))\n",
        "\n",
        "    # Remove the searched product from the recommendations\n",
        "    recs = recs.filter(col('distCol') != 1)\n",
        "\n",
        "\n",
        "    # Scale back distance of nearest neigbors in the unit vector space, ranges from 0 to sqrt(2)\n",
        "    recs = recs.withColumn('distCol', math.sqrt(2) - col('distCol') * math.sqrt(2))\n",
        "\n",
        "    # Scale back purchase_per_view rate, ranges from 0 to 0.075\n",
        "    recs = recs.withColumn('purchase_per_view', col('purchase_per_view') * 0.075)\n",
        "\n",
        "    # Scale back relative price value, ranges from -5 to 5\n",
        "    recs = recs.withColumn('relative_price', col('relative_price') * 10 - 5)\n",
        "\n",
        "    # Scale product's average relative price value, ranges from -5 to 5\n",
        "    product_relative_price = product_relative_price * 10 - 5\n",
        "\n",
        "    return recs"
      ],
      "metadata": {
        "id": "_uvYsxI0GLgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recs_product = calculate_recommendation_scores_for_products(neighbors.select('product_id', 'distCol'), products)"
      ],
      "metadata": {
        "id": "-5Yu4kCrGLgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display recommendations with Pandas\n",
        "\n",
        "recs_product.sort('recommendation_score', ascending=False).toPandas()\n"
      ],
      "metadata": {
        "scrolled": true,
        "id": "eWb73-Z8GLgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recommend Products to Users Product Pair"
      ],
      "metadata": {
        "id": "OW_TqB2rGLgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recs_user = recs_user.withColumnRenamed('recommendation_score', 'recommendation_score_user')\n",
        "recs_paired = recs_product.join(recs_user['product_id', 'recommendation_score_user'], on='product_id', how='left')"
      ],
      "metadata": {
        "id": "RTym9E4kGLgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "min_user_score = recs_paired.select(min('recommendation_score_user')).collect()[0][0]\n",
        "recs_paired = recs_paired.na.fill(min_user_score * 0.9)\n",
        "\n",
        "# weighted equally\n",
        "recs_paired = recs_paired.withColumn('paired_score', col('recommendation_score') * 0.5 + col('recommendation_score_user') * 0.5)\n"
      ],
      "metadata": {
        "id": "Z1IH0g1oGLgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recs_paired.sort('paired_score', ascending=False).toPandas()\n"
      ],
      "metadata": {
        "scrolled": true,
        "id": "j0M3jdRfGLgz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}